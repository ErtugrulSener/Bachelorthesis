% !TeX root = ../Bachelorarbeit.tex
\chapter{Auswertung}
Das Passwort war jahrzehntelanger Vorherrscher in der Authentifikation im Web und schien eine kurze Weile auch sicher. Nach dem die ersten Bruteforce-Angriffe auf Formulare angeggangen wurden, mussten neue Regeln für Passwörter her. Der Nutzer durfte sie nicht mehr nach eigenem Ermessen wählen, da der Imageschaden durch z.B: die Infiltrierung einer wichtigen hochrangigen Person eines Unternehmens zu groß wurde. Die Fälle der Data-Breaches und Leaks wurden trotz Passwort-Policy Ansätzen und der Einführung des zweiten Faktors nicht weniger sondern im Gegenteil: Sie häuften sich mehr und mehr. Passwörter wurden theoretisch durch erzwungene Sonderzeichen und einer Mindestlänge komplexer, allerdings wurde genau hier nicht mit der Natur des Menschen gerechnet. Da Formulare nun mehr und mehr Passwörter abzulehnen schienen, beggangen Menschen die Sicherheitsfeatures instinktiv zu umgehen. Darauf folgten die 'zeitlich begrenzten Passwörter', welche aus dem selben Grund, dem Bequemlichkeitsproblem, scheiterten. Neuere Verfahren sollten die alteingesessenen ersetzen oder zunächst ein Mal unterstützen. Die neue Zeit des Smartphones ermöglichte den Nutzern ihre Geräte zur Authentifikation zu nutzen, wofür sie davor kostspielige Geräte kaufen hätten müssen. Die Zeit der Einmalkennwörter brach an und Apps wie der Google Authenticator oder der Microsoft Authenticator gewannen mehr und mehr an Popularität. Mit der Zeit wurden allerdings auch diese 'weiteren Schritte' zur Authentifikation dem Nutzer zu lästig. Vor allem wichtige Dienste wie Banken führen kein Sessionmanagement und nötigen den User häufig zur mehrmaligen Authentifikation während einer Sitzung. Und genau an diesem Standpunkt setzen die neuesten Verfahren an. Die Webauthentikation ist dem Passwort in vielen Dingen überlegen. Zunächst ein Mal werden nur noch zufällig generierte Schlüssel ausgetauscht. Außerdem geschieht das über Challenge-Response-Verfahren wodurch Wiederholungsangriffe vermieden werden. Der Nutzer ist nicht mehr der Kern der Authentifikation sondern der Authentifikator (das Gerät) selbst. Bei neueren public-private-key Verfahren gibt es keine Geheimnisse, die auf einfachste Art und Weise (z.B: über Keylogger, Trojaner oder Shoulder Surfing) entwendet werden könnten. Die Verantworung zur sicheren Aufbewahrung von Passwörtern hat sich vom Nutzer auf die Betriebssysteme verschoben, die die privaten Schlüssel sichern müssen. Die Kommunikation ist dann durch den \ac{mitm} angreifbar, wenn der Aussteller des Zertifikats nicht bekannt ist. Die Webauthentikation bietet einem Mann in der Mitte allerdings keine einfache Möglichkeit, die Identität des Nutzers anzunehmen. Der FIDO2 - Standard definiert mit Webauthn und CTAP2 die Kommunikation über verschiedenste Authentifikatoren. Dennoch ist Handling des Hauptbetriebssystems Windows aus UX-Sicht nur suboptimal. Gleichzeitig ist die Implementation von Webauthn auf Clientseite zwar schon integriert in die neuesten Browser, auf Serverseite fehlt es bei Javascript basierenden Webseiten aber an ausgereiften Web-API's. Die Abstraktion der Vorgänge im Webauthn - Protokoll durch vorhandene API's (wie die genutze im Prototyp) hat den Vorteil, dass der Implementationsaufwand durch eine Senkung der Komplexität sinkt. Gleichzeitig muss bei Fehlern in der abstrahierten Bibliothek ein Mehraufwand an Verständnis dessen, was die Bibliothek macht, aufgetrieben werden. Gemessen daran, dass man das Protokoll allerdings nur einmalig implementieren muss und die FIDO-Alliance große Unterstützung für Webseiten für alle möglichen Programmiersprachen bietet, scheint dieses Argument entkräftigt.

Die Frage die sich nun stellt ist es, ob jeder Nutzer auf neuere Authentifikationsverfahren umsteigen sollte.
